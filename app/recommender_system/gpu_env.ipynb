{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gpu_env.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zYl6tMst7593","executionInfo":{"status":"ok","timestamp":1619461228440,"user_tz":420,"elapsed":1957,"user":{"displayName":"Matthew Buchholz","photoUrl":"","userId":"01030673411075823670"}},"outputId":"57a43e1f-c083-4f42-bd1b-449a155d4f7a"},"source":["from google.colab import drive\n","\n","ROOT = \"/content/drive\"\n","print(ROOT)\n","drive.mount(ROOT, force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/content/drive\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1K5jqlHH8TdI","executionInfo":{"status":"ok","timestamp":1619461228441,"user_tz":420,"elapsed":1946,"user":{"displayName":"Matthew Buchholz","photoUrl":"","userId":"01030673411075823670"}},"outputId":"1f0990ed-2d66-4d30-f7e3-c923b40027a6"},"source":["%cd './drive/MyDrive/491B_AniMe/app/recommender_system/'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/491B_AniMe/app/recommender_system\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"x6Wb3cuOlmrY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619471695234,"user_tz":420,"elapsed":10464959,"user":{"displayName":"Matthew Buchholz","photoUrl":"","userId":"01030673411075823670"}},"outputId":"cd0a3ff8-38d6-4c58-ad2e-cc7e384862bd"},"source":["!python train.py"],"execution_count":3,"outputs":[{"output_type":"stream","text":["---------------------------------------\n","Loading data\n","---------------------------------------\n","\n","100% 24755/24755 [02:57<00:00, 139.35it/s]\n","Epoch 1/100 ...... Training loss: 23.807168116113967\n","100% 24755/24755 [02:56<00:00, 139.97it/s]\n","Epoch 2/100 ...... Training loss: 12.86678759328911\n","100% 24755/24755 [02:56<00:00, 139.91it/s]\n","Epoch 3/100 ...... Training loss: 10.994964312447657\n","100% 24755/24755 [02:56<00:00, 140.22it/s]\n","Epoch 4/100 ...... Training loss: 9.727985801727597\n","100% 24755/24755 [02:56<00:00, 140.08it/s]\n","Epoch 5/100 ...... Training loss: 8.705873683774575\n","100% 24755/24755 [02:56<00:00, 139.90it/s]\n","Epoch 6/100 ...... Training loss: 7.833807536255974\n","100% 24755/24755 [02:56<00:00, 139.98it/s]\n","Epoch 7/100 ...... Training loss: 7.069167028140887\n","100% 24755/24755 [02:56<00:00, 139.98it/s]\n","Epoch 8/100 ...... Training loss: 6.389135370599311\n","100% 24755/24755 [02:57<00:00, 139.82it/s]\n","Epoch 9/100 ...... Training loss: 5.779832888911214\n","100% 24755/24755 [02:57<00:00, 139.83it/s]\n","Epoch 10/100 ...... Training loss: 5.231761693386232\n","100% 24755/24755 [02:57<00:00, 139.70it/s]\n","Epoch 11/100 ...... Training loss: 4.737600343084364\n","100% 24755/24755 [02:56<00:00, 139.86it/s]\n","Epoch 12/100 ...... Training loss: 4.291448055414498\n","100% 24755/24755 [02:56<00:00, 140.00it/s]\n","Epoch 13/100 ...... Training loss: 3.8882737588988388\n","100% 24755/24755 [02:57<00:00, 139.70it/s]\n","Epoch 14/100 ...... Training loss: 3.5237463958719433\n","100% 24755/24755 [02:56<00:00, 140.03it/s]\n","Epoch 15/100 ...... Training loss: 3.194043195534176\n","100% 24755/24755 [02:56<00:00, 139.97it/s]\n","Epoch 16/100 ...... Training loss: 2.8957424841560853\n","100% 24755/24755 [02:56<00:00, 139.97it/s]\n","Epoch 17/100 ...... Training loss: 2.6258178694275647\n","100% 24755/24755 [02:56<00:00, 140.16it/s]\n","Epoch 18/100 ...... Training loss: 2.3815343850936537\n","100% 24755/24755 [02:56<00:00, 139.93it/s]\n","Epoch 19/100 ...... Training loss: 2.1604227967706264\n","100% 24755/24755 [02:56<00:00, 139.91it/s]\n","Epoch 20/100 ...... Training loss: 1.9602859586110093\n","100% 24755/24755 [02:56<00:00, 139.94it/s]\n","Epoch 21/100 ...... Training loss: 1.7791079211538428\n","100% 24755/24755 [02:57<00:00, 139.85it/s]\n","Epoch 22/100 ...... Training loss: 1.6150912694896358\n","100% 24755/24755 [02:56<00:00, 139.92it/s]\n","Epoch 23/100 ...... Training loss: 1.4666020983856054\n","100% 24755/24755 [02:57<00:00, 139.52it/s]\n","Epoch 24/100 ...... Training loss: 1.332160659299622\n","100% 24755/24755 [02:57<00:00, 139.44it/s]\n","Epoch 25/100 ...... Training loss: 1.210441735281508\n","100% 24755/24755 [02:57<00:00, 139.78it/s]\n","Epoch 26/100 ...... Training loss: 1.1002347781282078\n","100% 24755/24755 [02:56<00:00, 139.95it/s]\n","Epoch 27/100 ...... Training loss: 1.0004490832299133\n","100% 24755/24755 [02:56<00:00, 140.00it/s]\n","Epoch 28/100 ...... Training loss: 0.9100979581020789\n","100% 24755/24755 [02:56<00:00, 139.96it/s]\n","Epoch 29/100 ...... Training loss: 0.8282834277685617\n","100% 24755/24755 [02:56<00:00, 140.00it/s]\n","Epoch 30/100 ...... Training loss: 0.7542025818677411\n","100% 24755/24755 [02:56<00:00, 140.01it/s]\n","Epoch 31/100 ...... Training loss: 0.6871187422088217\n","100% 24755/24755 [02:56<00:00, 139.93it/s]\n","Epoch 32/100 ...... Training loss: 0.6263725932596477\n","100% 24755/24755 [02:56<00:00, 140.04it/s]\n","Epoch 33/100 ...... Training loss: 0.57136304021917\n","100% 24755/24755 [02:56<00:00, 140.02it/s]\n","Epoch 34/100 ...... Training loss: 0.5215461831819022\n","100% 24755/24755 [02:56<00:00, 139.90it/s]\n","Epoch 35/100 ...... Training loss: 0.47643151541258005\n","100% 24755/24755 [02:57<00:00, 139.62it/s]\n","Epoch 36/100 ...... Training loss: 0.4355722053090483\n","100% 24755/24755 [02:57<00:00, 139.85it/s]\n","Epoch 37/100 ...... Training loss: 0.3985674773110594\n","100% 24755/24755 [02:57<00:00, 139.65it/s]\n","Epoch 38/100 ...... Training loss: 0.36505033168328505\n","100% 24755/24755 [02:57<00:00, 139.80it/s]\n","Epoch 39/100 ...... Training loss: 0.3346914863868136\n","100% 24755/24755 [02:57<00:00, 139.71it/s]\n","Epoch 40/100 ...... Training loss: 0.30719159186259587\n","100% 24755/24755 [02:57<00:00, 139.80it/s]\n","Epoch 41/100 ...... Training loss: 0.28227882099690954\n","100% 24755/24755 [02:56<00:00, 139.91it/s]\n","Epoch 42/100 ...... Training loss: 0.259709097225602\n","100% 24755/24755 [02:57<00:00, 139.84it/s]\n","Epoch 43/100 ...... Training loss: 0.2392625157868253\n","100% 24755/24755 [02:57<00:00, 139.34it/s]\n","Epoch 44/100 ...... Training loss: 0.22073219036952435\n","100% 24755/24755 [02:57<00:00, 139.61it/s]\n","Epoch 45/100 ...... Training loss: 0.20394318408735881\n","100% 24755/24755 [02:57<00:00, 139.67it/s]\n","Epoch 46/100 ...... Training loss: 0.18872838208252096\n","100% 24755/24755 [02:57<00:00, 139.59it/s]\n","Epoch 47/100 ...... Training loss: 0.17494008740230754\n","100% 24755/24755 [02:56<00:00, 139.94it/s]\n","Epoch 48/100 ...... Training loss: 0.16244391954275025\n","100% 24755/24755 [02:57<00:00, 139.41it/s]\n","Epoch 49/100 ...... Training loss: 0.1511178413856345\n","100% 24755/24755 [02:57<00:00, 139.71it/s]\n","Epoch 50/100 ...... Training loss: 0.14085353598934644\n","100% 24755/24755 [02:57<00:00, 139.48it/s]\n","Epoch 51/100 ...... Training loss: 0.13154954766593926\n","100% 24755/24755 [02:57<00:00, 139.62it/s]\n","Epoch 52/100 ...... Training loss: 0.12311474679335516\n","100% 24755/24755 [02:57<00:00, 139.74it/s]\n","Epoch 53/100 ...... Training loss: 0.11546928764497168\n","100% 24755/24755 [02:57<00:00, 139.78it/s]\n","Epoch 54/100 ...... Training loss: 0.10853977067660525\n","100% 24755/24755 [02:57<00:00, 139.63it/s]\n","Epoch 55/100 ...... Training loss: 0.10225563847526255\n","100% 24755/24755 [02:57<00:00, 139.59it/s]\n","Epoch 56/100 ...... Training loss: 0.09655732855552905\n","100% 24755/24755 [02:57<00:00, 139.81it/s]\n","Epoch 57/100 ...... Training loss: 0.09139158570707458\n","100% 24755/24755 [02:57<00:00, 139.78it/s]\n","Epoch 58/100 ...... Training loss: 0.08670525428858027\n","100% 24755/24755 [02:56<00:00, 139.90it/s]\n","Epoch 59/100 ...... Training loss: 0.08245435751789484\n","  1% 204/24755 [00:02<04:02, 101.25it/s]\n","Traceback (most recent call last):\n","  File \"train.py\", line 22, in <module>\n","    train(model_dict, train_loader, num_epochs)\n","  File \"/content/drive/My Drive/491B_AniMe/app/recommender_system/utils.py\", line 101, in train\n","    losses.append(loss.item())\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qkAGJShlloL_"},"source":[""],"execution_count":null,"outputs":[]}]}